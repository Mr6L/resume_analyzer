from flask import Flask, request, jsonify
from werkzeug.utils import secure_filename
import os
import uuid
import logging
import traceback
from datetime import datetime
from resume_parser import ResumeParser
from deepseek_analyzer import DeepSeekAnalyzer
from dotenv import load_dotenv

# åŠ è½½é…ç½®æ–‡ä»¶
load_dotenv('../config.env')

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('resume_analyzer.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

app = Flask(__name__)
app.config['SECRET_KEY'] = 'resume_analyzer_secret_key'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size

logger.info("ğŸš€ å¯åŠ¨ç®€å†åˆ†æç³»ç»Ÿåç«¯æœåŠ¡...")

# é…ç½®æ–‡ä»¶ä¸Šä¼ è·¯å¾„
UPLOAD_FOLDER = '../uploads'
TEMP_FOLDER = '../temp'

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(TEMP_FOLDER, exist_ok=True)
logger.info(f"ğŸ“ ä¸Šä¼ ç›®å½•: {os.path.abspath(UPLOAD_FOLDER)}")
logger.info(f"ğŸ“ ä¸´æ—¶ç›®å½•: {os.path.abspath(TEMP_FOLDER)}")

# å…è®¸çš„æ–‡ä»¶æ‰©å±•å
ALLOWED_EXTENSIONS = {'docx'}

# Grok APIå¯†é’¥ - ä»ç¯å¢ƒå˜é‡è·å–
GROK_API_KEY = os.getenv('GROK_API_KEY', 'YOUR_GROK_API_KEY')

if GROK_API_KEY == 'YOUR_GROK_API_KEY':
    logger.warning("âš ï¸  è­¦å‘Š: è¯·åœ¨config.envæ–‡ä»¶ä¸­è®¾ç½®æœ‰æ•ˆçš„GROK_API_KEY")
    logger.warning("   å½“å‰ä½¿ç”¨çš„æ˜¯é»˜è®¤å ä½ç¬¦å¯†é’¥ï¼ŒAIåˆ†æåŠŸèƒ½å°†ä¸å¯ç”¨")
else:
    logger.info(f"âœ… Grok APIå¯†é’¥å·²åŠ è½½: {GROK_API_KEY[:10]}...")

# åˆå§‹åŒ–è§£æå™¨å’Œåˆ†æå™¨
try:
    resume_parser = ResumeParser()
    analyzer = DeepSeekAnalyzer(GROK_API_KEY)  # ä¼ å…¥Grok APIå¯†é’¥ï¼Œç±»å†…éƒ¨ä¼šé€‚é…
    logger.info("âœ… ç®€å†è§£æå™¨å’ŒAIåˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    logger.error(f"âŒ åˆå§‹åŒ–è§£æå™¨å¤±è´¥: {str(e)}")
    logger.error(traceback.format_exc())


def allowed_file(filename):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å…è®¸ä¸Šä¼ """
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({'status': 'ok', 'message': 'æœåŠ¡æ­£å¸¸è¿è¡Œ'})


@app.route('/upload', methods=['POST'])
def upload_resume():
    """ä¸Šä¼ ç®€å†æ–‡ä»¶æ¥å£"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'æ²¡æœ‰æ–‡ä»¶ä¸Šä¼ '}), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400

        if not allowed_file(file.filename):
            return jsonify({'error': 'åªæ”¯æŒ.docxæ ¼å¼æ–‡ä»¶'}), 400

        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        filename = secure_filename(file.filename)
        unique_filename = f"{uuid.uuid4()}_{filename}"
        file_path = os.path.join(UPLOAD_FOLDER, unique_filename)

        # ä¿å­˜æ–‡ä»¶
        file.save(file_path)

        return jsonify({
            'success': True,
            'message': 'æ–‡ä»¶ä¸Šä¼ æˆåŠŸ',
            'file_id': unique_filename,
            'original_name': filename
        })

    except Exception as e:
        return jsonify({'error': f'ä¸Šä¼ å¤±è´¥: {str(e)}'}), 500


@app.route('/parse', methods=['POST'])
def parse_resume():
    """è§£æç®€å†æ¥å£"""
    try:
        data = request.get_json()
        if not data or 'file_id' not in data:
            return jsonify({'error': 'ç¼ºå°‘file_idå‚æ•°'}), 400

        file_id = data['file_id']
        file_path = os.path.join(UPLOAD_FOLDER, file_id)

        if not os.path.exists(file_path):
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404

        # è§£æç®€å†
        parsed_data = resume_parser.parse_resume(file_path)

        return jsonify({
            'success': True,
            'data': parsed_data
        })

    except Exception as e:
        return jsonify({'error': f'è§£æå¤±è´¥: {str(e)}'}), 500


@app.route('/analyze', methods=['POST'])
def analyze_resume():
    """åˆ†æç®€å†å¹¶æä¾›å»ºè®®"""
    try:
        data = request.get_json()
        if not data or 'resume_data' not in data:
            return jsonify({'error': 'ç¼ºå°‘resume_dataå‚æ•°'}), 400

        resume_data = data['resume_data']

        # ä½¿ç”¨DeepSeekåˆ†æç®€å†
        analysis_result = analyzer.analyze_resume(resume_data)

        if not analysis_result['success']:
            return jsonify({'error': analysis_result['error']}), 500

        return jsonify({
            'success': True,
            'analysis': analysis_result['analysis'],
            'raw_analysis': analysis_result['raw_analysis']
        })

    except Exception as e:
        return jsonify({'error': f'åˆ†æå¤±è´¥: {str(e)}'}), 500


@app.route('/recommend_jobs', methods=['POST'])
def recommend_jobs():
    """æ¨èå²—ä½æ¥å£"""
    try:
        data = request.get_json()
        if not data or 'resume_data' not in data:
            return jsonify({'error': 'ç¼ºå°‘resume_dataå‚æ•°'}), 400

        resume_data = data['resume_data']

        # ç”Ÿæˆå²—ä½æ¨è
        recommendation_result = analyzer.generate_job_recommendations(resume_data)

        if not recommendation_result['success']:
            return jsonify({'error': recommendation_result['error']}), 500

        return jsonify({
            'success': True,
            'recommendations': recommendation_result['recommendations']
        })

    except Exception as e:
        return jsonify({'error': f'æ¨èå¤±è´¥: {str(e)}'}), 500


@app.route('/full_analysis', methods=['POST'])
def full_analysis():
    """å®Œæ•´åˆ†ææµç¨‹ï¼šä¸Šä¼ ->è§£æ->åˆ†æ->æ¨è"""
    request_id = str(uuid.uuid4())[:8]
    logger.info(f"ğŸ” [{request_id}] å¼€å§‹å®Œæ•´åˆ†ææµç¨‹")

    try:
        # 1. æ£€æŸ¥æ–‡ä»¶ä¸Šä¼ 
        logger.debug(f"[{request_id}] æ£€æŸ¥æ–‡ä»¶ä¸Šä¼ ...")
        if 'file' not in request.files:
            logger.error(f"[{request_id}] æ²¡æœ‰æ–‡ä»¶ä¸Šä¼ ")
            return jsonify({'error': 'æ²¡æœ‰æ–‡ä»¶ä¸Šä¼ '}), 400

        file = request.files['file']
        logger.info(f"[{request_id}] æ¥æ”¶åˆ°æ–‡ä»¶: {file.filename}")

        if file.filename == '':
            logger.error(f"[{request_id}] æ²¡æœ‰é€‰æ‹©æ–‡ä»¶")
            return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400

        if not allowed_file(file.filename):
            logger.error(f"[{request_id}] æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ: {file.filename}")
            return jsonify({'error': 'åªæ”¯æŒ.docxæ ¼å¼æ–‡ä»¶'}), 400

        # 2. ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        logger.debug(f"[{request_id}] ä¿å­˜ä¸´æ—¶æ–‡ä»¶...")
        filename = secure_filename(file.filename)
        temp_filename = f"{uuid.uuid4()}_{filename}"
        temp_file_path = os.path.join(TEMP_FOLDER, temp_filename)
        logger.info(f"[{request_id}] ä¸´æ—¶æ–‡ä»¶è·¯å¾„: {temp_file_path}")

        file.save(temp_file_path)
        file_size = os.path.getsize(temp_file_path)
        logger.info(f"[{request_id}] æ–‡ä»¶ä¿å­˜æˆåŠŸï¼Œå¤§å°: {file_size} bytes")

        try:
            # 3. è§£æç®€å†
            logger.info(f"[{request_id}] å¼€å§‹è§£æç®€å†...")
            parsed_data = resume_parser.parse_resume(temp_file_path)
            logger.info(f"[{request_id}] ç®€å†è§£ææˆåŠŸ")
            logger.debug(f"[{request_id}] è§£æç»“æœ: {list(parsed_data.keys())}")

            # 4. AIåˆ†æ
            logger.info(f"[{request_id}] å¼€å§‹AIåˆ†æ...")
            analysis_result = analyzer.analyze_resume(parsed_data)
            if analysis_result['success']:
                logger.info(f"[{request_id}] AIåˆ†ææˆåŠŸ")
            else:
                logger.error(f"[{request_id}] AIåˆ†æå¤±è´¥: {analysis_result['error']}")

            # 5. å²—ä½æ¨è
            logger.info(f"[{request_id}] å¼€å§‹å²—ä½æ¨è...")
            recommendation_result = analyzer.generate_job_recommendations(parsed_data)
            if recommendation_result['success']:
                logger.info(f"[{request_id}] å²—ä½æ¨èæˆåŠŸ")
            else:
                logger.error(f"[{request_id}] å²—ä½æ¨èå¤±è´¥: {recommendation_result['error']}")

            # 6. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_file_path):
                os.remove(temp_file_path)
                logger.debug(f"[{request_id}] ä¸´æ—¶æ–‡ä»¶å·²åˆ é™¤")

            logger.info(f"[{request_id}] å®Œæ•´åˆ†ææµç¨‹å®Œæˆ")
            return jsonify({
                'success': True,
                'original_filename': filename,
                'parsed_data': parsed_data,
                'analysis': analysis_result['analysis'] if analysis_result['success'] else None,
                'recommendations': recommendation_result['recommendations'] if recommendation_result['success'] else None,
                'errors': {
                    'analysis_error': None if analysis_result['success'] else analysis_result['error'],
                    'recommendation_error': None if recommendation_result['success'] else recommendation_result['error']
                }
            })

        except Exception as e:
            # ç¡®ä¿åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_file_path):
                os.remove(temp_file_path)
                logger.debug(f"[{request_id}] å¼‚å¸¸æ—¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶")
            raise e

    except Exception as e:
        logger.error(f"[{request_id}] åˆ†æè¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        logger.error(f"[{request_id}] å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
        return jsonify({'error': f'åˆ†æå¤±è´¥: {str(e)}'}), 500


@app.errorhandler(413)
def too_large(e):
    """æ–‡ä»¶è¿‡å¤§é”™è¯¯å¤„ç†"""
    return jsonify({'error': 'æ–‡ä»¶è¿‡å¤§ï¼Œè¯·ä¸Šä¼ å°äº16MBçš„æ–‡ä»¶'}), 413


@app.errorhandler(500)
def internal_error(e):
    """æœåŠ¡å™¨å†…éƒ¨é”™è¯¯å¤„ç†"""
    return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500


if __name__ == '__main__':
    print("å¯åŠ¨ç®€å†åˆ†æåç«¯æœåŠ¡...")
    print(f"ä¸Šä¼ ç›®å½•: {os.path.abspath(UPLOAD_FOLDER)}")
    print(f"ä¸´æ—¶ç›®å½•: {os.path.abspath(TEMP_FOLDER)}")
    print("è¯·ç¡®ä¿å·²è®¾ç½®DeepSeek APIå¯†é’¥")
    app.run(host='127.0.0.1', port=5000, debug=True)